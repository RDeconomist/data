{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US Income Data\n",
    "\n",
    "What I want:\n",
    "</br>\n",
    "<img width='500px' src=\"target_sketch.jpeg\"></img>\n",
    "</br>\n",
    "What I have:\n",
    "</br>\n",
    "\n",
    "<img width='500px' src=\"start_shot.png\"></img>\n",
    "</br>\n",
    "What I need to do:\n",
    "* Load in each sheet to temp dfs\n",
    "* Melt\n",
    "* Add series and view cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "wd = '/Users/finn/Documents/GitHub/data/e4e3' #Path of e4e3 folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First the Income by Percentiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Series</th>\n",
       "      <th>Income</th>\n",
       "      <th>View</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>20th</td>\n",
       "      <td>28007</td>\n",
       "      <td>by Percentile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>20th</td>\n",
       "      <td>28544</td>\n",
       "      <td>by Percentile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>20th</td>\n",
       "      <td>29762</td>\n",
       "      <td>by Percentile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>20th</td>\n",
       "      <td>27621</td>\n",
       "      <td>by Percentile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>20th</td>\n",
       "      <td>27435</td>\n",
       "      <td>by Percentile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1971</td>\n",
       "      <td>95th</td>\n",
       "      <td>144394</td>\n",
       "      <td>by Percentile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>1970</td>\n",
       "      <td>95th</td>\n",
       "      <td>144708</td>\n",
       "      <td>by Percentile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>1969</td>\n",
       "      <td>95th</td>\n",
       "      <td>142828</td>\n",
       "      <td>by Percentile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>1968</td>\n",
       "      <td>95th</td>\n",
       "      <td>135852</td>\n",
       "      <td>by Percentile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1967</td>\n",
       "      <td>95th</td>\n",
       "      <td>135134</td>\n",
       "      <td>by Percentile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year Series  Income           View\n",
       "0    2021   20th   28007  by Percentile\n",
       "1    2020   20th   28544  by Percentile\n",
       "2    2019   20th   29762  by Percentile\n",
       "3    2018   20th   27621  by Percentile\n",
       "4    2017   20th   27435  by Percentile\n",
       "..    ...    ...     ...            ...\n",
       "280  1971   95th  144394  by Percentile\n",
       "281  1970   95th  144708  by Percentile\n",
       "282  1969   95th  142828  by Percentile\n",
       "283  1968   95th  135852  by Percentile\n",
       "284  1967   95th  135134  by Percentile\n",
       "\n",
       "[285 rows x 4 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(f'{wd}/Uncleaned Data/US Quintiles Incomes 1967-2021.xlsx',skiprows=68)\n",
    "df.columns = ['Year', 'n', '20th', '40th', '60th', '80th', '95th']\n",
    "df['Year'] = df['Year'].astype(str).str[0:4] # Some Years have notes, let's lose these\n",
    "df = df\n",
    "df = df.loc[:, df.columns != 'n'] #don't care about n\n",
    "df = pd.melt(df, id_vars=['Year'], var_name='Series', value_name='Income')\n",
    "df['View'] = 'by Percentile'\n",
    "\n",
    "pctile_df = df\n",
    "pctile_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then by Race:\n",
    "Have one sheet with lots of tables. Let's define a list of lists to store race and row number for each then loop over. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_races = [\n",
    "    ['All Races', 8],\n",
    "    ['White Alone', 68],\n",
    "    ['White', 93],\n",
    "    ['White Alone, Not Hispanic', 131],\n",
    "    ['White, Not Hispanic', 156],\n",
    "    ['Black Alone or in Combination', 189],\n",
    "    ['Black Alone', 214],\n",
    "    ['Black', 239],\n",
    "    ['Asian Alone or in Combination', 277],\n",
    "    ['Asian Alone', 302],\n",
    "    ['Asian and Pacific Islander', 327],\n",
    "    ['Hispanic (any race)', 345]] #Used to loop over document, selecting each race-income table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df = None\n",
    "for race, row in rows_races:\n",
    "    df = pd.read_excel(f'{wd}/Uncleaned Data/US Median Income By Year and Race 1967-.xlsx',skiprows=row)\n",
    "    df.columns = ['Year', 'n', 'Median (Current USD)', 'Income',  'Mean (Current USD)', 'Mean (2021 USD)']\n",
    "    df = df[['Year', 'Income']] #Only care about current dollars real incomes\n",
    "    df['Year'] = df['Year'].astype(str).str[0:4] # Some Years have notes, let's lose these\n",
    "    df['Series'] = race\n",
    "    #We only want to read until the end of the current table not the whole sheet, so:\n",
    "    if len(df.index[df.iloc[:, 1].isna()])>0: #Check if there are any empty rows [end of table]\n",
    "        first_empty_row = df.index[df.iloc[:, 1].isna()][0] #1. Find first empty row if there are\n",
    "        df = df.iloc[:first_empty_row, :] #2. lose all after that\n",
    "    if race_df is None:\n",
    "        race_df = df\n",
    "    else:\n",
    "        race_df = pd.concat([race_df, df], ignore_index=True)\n",
    "#Have some (~5 rows) missing data, let's lose those rows\n",
    "race_df = race_df[race_df['Income'] != 'N']\n",
    "race_df['View'] = 'by Race'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['All Races', 'White Alone', 'White', 'White Alone, Not Hispanic',\n",
       "       'White, Not Hispanic', 'Black Alone or in Combination',\n",
       "       'Black Alone', 'Black', 'Asian Alone or in Combination',\n",
       "       'Asian Alone', 'Asian and Pacific Islander', 'Hispanic (any race)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_df.Series.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Binding pre-2001 racial categories to post-2021 racial categories </b>\n",
    "\n",
    "In 2001, racial categories changed. Let's reduce down to a simple (oversimple?) set: White (Non Hispanic), Hispanic, Black, Asian and Pacific Islander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebinds = {\n",
    "    'White Alone, Not Hispanic' : 'White, Not Hispanic',\n",
    "    'Black Alone or in Combination' : 'Black',\n",
    "    'Black Alone' : 'Black',\n",
    "    'Black' : 'Black',\n",
    "    'White, Not Hispanic' : 'White, Not Hispanic',\n",
    "    'Asian Alone' : 'Asian',\n",
    "    'Asian and Pacific Islander': 'Asian',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df = race_df.replace({\"Series\":rebinds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Income</th>\n",
       "      <th>Series</th>\n",
       "      <th>View</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2021</td>\n",
       "      <td>48815</td>\n",
       "      <td>Black</td>\n",
       "      <td>by Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2020</td>\n",
       "      <td>48936</td>\n",
       "      <td>Black</td>\n",
       "      <td>by Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2019</td>\n",
       "      <td>48827</td>\n",
       "      <td>Black</td>\n",
       "      <td>by Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2018</td>\n",
       "      <td>44984</td>\n",
       "      <td>Black</td>\n",
       "      <td>by Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2017</td>\n",
       "      <td>44197</td>\n",
       "      <td>Black</td>\n",
       "      <td>by Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1971</td>\n",
       "      <td>33368</td>\n",
       "      <td>Black</td>\n",
       "      <td>by Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1970</td>\n",
       "      <td>34574</td>\n",
       "      <td>Black</td>\n",
       "      <td>by Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1969</td>\n",
       "      <td>34672</td>\n",
       "      <td>Black</td>\n",
       "      <td>by Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>1968</td>\n",
       "      <td>32536</td>\n",
       "      <td>Black</td>\n",
       "      <td>by Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1967</td>\n",
       "      <td>30761</td>\n",
       "      <td>Black</td>\n",
       "      <td>by Race</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year Income Series     View\n",
       "166  2021  48815  Black  by Race\n",
       "167  2020  48936  Black  by Race\n",
       "168  2019  48827  Black  by Race\n",
       "169  2018  44984  Black  by Race\n",
       "170  2017  44197  Black  by Race\n",
       "..    ...    ...    ...      ...\n",
       "240  1971  33368  Black  by Race\n",
       "241  1970  34574  Black  by Race\n",
       "242  1969  34672  Black  by Race\n",
       "243  1968  32536  Black  by Race\n",
       "244  1967  30761  Black  by Race\n",
       "\n",
       "[79 rows x 4 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_df.query(\"Series == 'Black'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df = race_df[race_df['Series'].isin(list(rebinds.values())+['Hispanic (any race)', 'All Races'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df = race_df.groupby(['Year', 'Series']).aggregate({'Income': 'first'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df.Series.value_counts()\n",
    "race_df['View'] = 'by Race'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### and finally by Region:\n",
    "Have one sheet with lots of tables. Let's define a list of lists to store race and row number for each then loop over. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_regions = [\n",
    "    ['United States', 8],\n",
    "    ['Northeast', 60],\n",
    "    ['Midwest', 112],\n",
    "    ['South', 164],\n",
    "    ['West', 216]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_df = None\n",
    "for region, row in rows_regions:\n",
    "    df = pd.read_excel(f'{wd}/Uncleaned Data/US Median Incomes by Region.xlsx',skiprows=row)\n",
    "    df.columns = ['Year', 'n', 'Median (Current USD)', 'Income',  'Mean (Current USD)', 'Mean (2021 USD)']\n",
    "    df = df[['Year', 'Income']] #Only care about current dollars real incomes\n",
    "    df['Year'] = df['Year'].astype(str).str[0:4] # Some Years have notes, let's lose these\n",
    "    df['Series'] = region\n",
    "    #We only want to read until the end of the current table not the whole sheet, so:\n",
    "    if len(df.index[df.iloc[:, 1].isna()])>0: #Check if there are any empty rows [end of table]\n",
    "        first_empty_row = df.index[df.iloc[:, 1].isna()][0] #1. Find first empty row if there are\n",
    "        df = df.iloc[:first_empty_row, :] #2. lose all after that\n",
    "    if region_df is None:\n",
    "        region_df = df\n",
    "    else:\n",
    "        region_df = pd.concat([region_df, df], ignore_index=True)\n",
    "#Have some (~5 rows) missing data, let's lose those rows\n",
    "region_df = region_df[region_df['Income'] != 'N']\n",
    "region_df['View'] = 'by Region'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing the 'All Races' to the quintiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pctile_df, race_df, region_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_df = df[df.Series == 'All Races'].copy()\n",
    "med_df.View = 'by Percentile'\n",
    "med_df.Series = 'Median'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, med_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Them All\n",
    "and exporting to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('us_incomes_pctile_race_region.csv', index=False)\n",
    "df.to_excel('us_incomes_pctile_race_region.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'by Percentile': ['20th', '40th', '60th', '80th', '95th', 'Median'],\n",
       " 'by Race': ['All Races',\n",
       "  'Black',\n",
       "  'Hispanic (any race)',\n",
       "  'White, Not Hispanic',\n",
       "  'Asian'],\n",
       " 'by Region': ['United States', 'Northeast', 'Midwest', 'South', 'West']}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Views = df.View.unique()\n",
    "{View:list(df.query(f\"View == '{View}'\")['Series'].unique()) for View in Views}\n",
    "\n",
    "# assemble vega expression\n",
    "expr = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20th',\n",
       " '40th',\n",
       " '60th',\n",
       " '80th',\n",
       " '95th',\n",
       " 'All Races',\n",
       " 'Black',\n",
       " 'Hispanic (any race)',\n",
       " 'White, Not Hispanic',\n",
       " 'Asian',\n",
       " 'United States',\n",
       " 'Northeast',\n",
       " 'Midwest',\n",
       " 'South',\n",
       " 'West',\n",
       " 'Median']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.Series.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.View.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
